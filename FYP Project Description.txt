Open-Domain Sentiment Analysis 	SCE16-0761

Most studies on sentiment analysis were conducted in a closed domain setting, where the training and test data are assumed to share a similar vocabulary. However, this assumption does not hold in the context of social media, where the vocabulary is evolutional. In other words, there are always new words/phrases appearing in a social media over time. As a result, the sentiment lexicon built offline from the training data may be out of date when being used to make predictions. The objective of this project is to develop an open-domain sentiment analysis framework to address dynamic issue of vocabulary in social media. The proposed framework should be able to expand a sentiment lexicon for a social media dynamically and automatically. Moreover, the proposed framework should be computationally efficient to handle large-scale social posts generated daily by users in the social media.

Components

1) Crawler - Research on Twitter Streaming API, Continuous Polling, MongoDB Database to store data
2) Classifier - NLTK, Evolving lexicon, scikit-learn
3) Sentiment Lexicon Buffer to capture words with a score so to re-classify and imply their sentiment based on the surrounding words in the tweet.

pipreqs used for requirements.txt

Research NLP techniques - MultinomialNB, GaussianNB, LinearSVC, SVM, Ensemble Classifier
POS tags - Penn Treebank Part-Of-Speech Tags
Dependency Parser
Sentiment Dictionary

Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014. -> Sentiment Analysis Tool

The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.
The pos, neu, and neg scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation). These are the most useful metrics if you want multidimensional measures of sentiment for a given sentence.

Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit
Steven Bird, Ewan Klein, and Edward Loper